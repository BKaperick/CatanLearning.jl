{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "using Random\n",
    "using CSV\n",
    "using MLJ\n",
    "using DataFrames\n",
    "import DataFramesMeta as DFM\n",
    "using DelimitedFiles\n",
    "using MLJScikitLearnInterface\n",
    "#df = DataFrame(CSV.File(ARGS[1]))\n",
    "#df = DataFrame(\"../../features.csv\")\n",
    "using Logging\n",
    "\n",
    "#logger = ConsoleLogger(stderr, Logging.Debug)\n",
    "#logger = ConsoleLogger(stderr, Logging.Info)\n",
    "#logger = ConsoleLogger(stderr, Logging.LogLevel(5000))\n",
    "#global_logger(logger)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_csv = \"../../data/features.csv\"\n",
    "data, header = readdlm(features_csv, ',', header=true)\n",
    "df = DataFrame(data, vec(header))\n",
    "for col in names(df)\n",
    "    println(col)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select!(df, Not([\n",
    "    :CountHandWood,\n",
    "    :CountHandBrick,\n",
    "    :CountHandPasture,\n",
    "    :CountHandStone,\n",
    "    :CountHandGrain,\n",
    "    :HasMostPoints,\n",
    "    :CountVictoryPoint\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "coerce!(df, :WonGame => Multiclass{2})\n",
    "df = DFM.@transform(df, :WonGame)\n",
    "df, df_test = partition(df, 0.1, rng=123)\n",
    "\n",
    "y, X = unpack(df, ==(:WonGame));\n",
    "y_test, X_test = unpack(df_test, ==(:WonGame));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function load_tree_model()\n",
    "    @load RandomForestClassifier pkg=BetaML verbosity=0\n",
    "end\n",
    "\n",
    "Tree = load_tree_model()\n",
    "tree = Base.invokelatest(Tree,\n",
    "    max_depth = 6,\n",
    "    min_gain = 0.0,\n",
    "    min_records = 2,\n",
    "    max_features = 0,\n",
    "    splitting_criterion = BetaML.Utils.gini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mach = machine(tree, X, y)\n",
    "Base.invokelatest(fit!, mach)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function analyze_acc(mach, X, y)\n",
    "    println(typeof(mach), typeof(X))\n",
    "    p = predict(mach, X)\n",
    "    yhat = mode.(p)\n",
    "    acc = accuracy(yhat, y)\n",
    "    return acc\n",
    "end\n",
    "\n",
    "acc = analyze_acc(mach, X, y)\n",
    "test_acc = analyze_acc(mach, X_test, y_test)\n",
    "println(\"acc / test_acc: $acc / $test_acc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = predict(mach, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p[1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collect(p)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf(p, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = coerce([0.0, 1.0], Multiclass)\n",
    "levels(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = pdf(p, levels(v))\n",
    "hcat(M, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_confusion(M, y_true, thresh = 0.5)\n",
    "    d = Dict([:fp => 0, :fn => 0, :tn => 0, :tp => 0])\n",
    "    n = size(M,1)\n",
    "    for i=1:n \n",
    "        if M[i,2] > thresh\n",
    "            if y_true[i] == 1.0\n",
    "                d[:tp] += 1\n",
    "            else\n",
    "                d[:fp] += 1\n",
    "            end\n",
    "        else\n",
    "            if y_true[i] == 1.0\n",
    "                d[:fn] += 1\n",
    "            else\n",
    "                d[:tn] += 1\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return d\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_confusion(M, y_test, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measures(\"FScore\")\n",
    "m = MulticlassFScore()\n",
    "m(mode.(p), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(mach, X_test)[1:3]\n",
    "e = evaluate!(mach, resampling=CV(nfolds=6), measures=[m, BalancedAccuracy(adjusted=true)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e.measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#r = range(tree, :threshold, lower=0.1, upper=0.9)\n",
    "tuned_tree = TunedModel(\n",
    "    models=[tree],\n",
    "    tuning=Explicit(),#RandomSearch(),\n",
    "    resampling=CV(nfolds=6),\n",
    "    range = nothing,#r,\n",
    "    measure=m,\n",
    "    n=30\n",
    ")\n",
    "mach2 = machine(tuned_tree, X, y) |> fit!\n",
    "optimized_tree = report(mach2).best_model\n",
    "optimized_tree.threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.4",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
